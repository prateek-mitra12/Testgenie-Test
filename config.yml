models:
  TestGenie:
    model_id: "anthropic.claude-3-5-sonnet-20240620-v1:0"
    # model_id: "anthropic.claude-3-sonnet-20240229-v1:0"
    input_format: "list_of_dicts"
    temperature: 0.5
    top_p: 1.0
    top_k: 500
    max_tokens: 200000
    memory_window: 10
    max_top_k: 500
  Deepseek:
    model_id: "anthropic.claude-3-haiku-20240307-v1:0"
    input_format: "list_of_dicts"
    temperature: 1.0
    top_p: 1.0
    top_k: 500
    max_tokens: 4096
    memory_window: 10
    max_top_k: 500
  Claude 3.5 Sonnet:
    model_id: "anthropic.claude-3-5-sonnet-20240620-v1:0"
    input_format: "list_of_dicts"
    temperature: 1.0
    top_p: 1.0
    top_k: 500
    max_tokens: 200000
    memory_window: 10
    max_top_k: 500
  Claude 3 Sonnet:
    model_id: "anthropic.claude-3-sonnet-20240229-v1:0"
    input_format: "list_of_dicts"
    temperature: 1.0
    top_p: 1.0
    top_k: 500
    max_tokens: 4096
    memory_window: 10
    max_top_k: 500
  Claude 3 Haiku:
    model_id: "anthropic.claude-3-haiku-20240307-v1:0"
    input_format: "list_of_dicts"
    temperature: 1.0
    top_p: 1.0
    top_k: 500
    max_tokens: 4096
    memory_window: 10
    max_top_k: 500
  Claude Instant:
    model_id: "anthropic.claude-instant-v1"
    input_format: "list_of_dicts"
    temperature: 1.0
    top_p: 1.0
    top_k: 500
    max_tokens: 4096
    memory_window: 10
    max_top_k: 500
  AI21 J2-Ultra:
    model_id: "ai21.j2-ultra-v1"
    input_format: "list_of_dicts"
    temperature: 1.0
    top_p: 1.0
    top_k: 500
    max_tokens: 4096
    memory_window: 10
    max_top_k: 500
  Mistral Large:
    model_id: "mistral.mistral-large-2402-v1:0"
    input_format: "list_of_dicts"
    system_prompt_disabled: true
    temperature: 1.0
    top_p: 1.0
    top_k: 200
    max_tokens: 4096
    memory_window: 10
    max_top_k: 200
    #image_upload_disabled: true
  LLaMA 3:
    model_id: "meta.llama3-70b-instruct-v1:0"
    input_format: "list_of_dicts"
    temperature: 1.0
    top_p: 1.0
    max_gen_len: 512
  LLaMA 2:
    model_id: "meta.llama2-70b-chat-v1"
    input_format: "list_of_dicts"
    temperature: 1.0
    top_p: 1.0
    max_gen_len: 512
  Amazon TitanText Premier:
    model_id: "amazon.titan-text-premier-v1:0"
    #system_prompt_disabled: true
    input_format: "list_of_dicts"
    temperature: 1.0
    topP: 1.0
    maxTokenCount: 4096
  Amazon TitanText Express:
    model_id: "amazon.titan-text-express-v1"
    #system_prompt_disabled: true
    input_format: "list_of_dicts"
    temperature: 1.0
    maxTokenCount: 8000
  OpenAI GPT4:
    model_id: "amazon.titan-text-express-v1"
    #system_prompt_disabled: true
    input_format: "list_of_dicts"
    temperature: 1.0
    maxTokenCount: 8000 
  Google Gemini Gemma:
    model_id: "amazon.titan-text-express-v1"
    #system_prompt_disabled: true
    input_format: "list_of_dicts"
    temperature: 1.0
    maxTokenCount: 8000
  # Currently routing between Claude 3 Sonnet, Claude 3.5 sonnet, Amazon TitanText Premier, Claude 3 Haiku, LLaMA 2.
  RouteLLM:    
    model_id: "anthropic.claude-3-sonnet-20240229-v1:0"
    temperature: 1.0
    topP: 1.0
    max_tokens: 32000
    top_k: 500
    memory_window : 10
    maxTokenCount: 32000
    system_prompt_disabled: true
    max_gen_len: 512




# models:
#   HCL TestGenie:
#     model_id: "anthropic.claude-3-5-sonnet-20240620-v1:0"
#     input_format: "list_of_dicts"
#     temperature: 0.5
#     top_p: 1.0
#     top_k: 500
#     max_tokens: 200000
#     memory_window: 10
#     max_top_k: 500
#   Claude 3 Sonnet:
#     model_id: "anthropic.claude-3-sonnet-20240229-v1:0"
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     top_p: 1.0
#     top_k: 500
#     max_tokens: 4096
#     memory_window: 10
#     max_top_k: 500
#   Claude 3 Haiku:
#     model_id: "anthropic.claude-3-haiku-20240307-v1:0"
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     top_p: 1.0
#     top_k: 500
#     max_tokens: 4096
#     memory_window: 10
#     max_top_k: 500
#   AI21 J2-Ultra:
#     model_id: "ai21.j2-ultra-v1"
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     top_p: 1.0
#     top_k: 500
#     max_tokens: 4096
#     memory_window: 10
#     max_top_k: 500
#   Mistral Large:
#     model_id: "mistral.mistral-large-2402-v1:0"
#     input_format: "list_of_dicts"
#     system_prompt_disabled: true
#     temperature: 1.0
#     top_p: 1.0
#     top_k: 200
#     max_tokens: 4096
#     memory_window: 10
#     max_top_k: 200
#     #image_upload_disabled: true
#   LLaMA 3:
#     model_id: "meta.llama3-70b-instruct-v1:0"
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     top_p: 1.0
#     max_gen_len: 512
#   LLaMA 2:
#     model_id: "meta.llama2-70b-chat-v1"
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     top_p: 1.0
#     max_gen_len: 512
#   Amazon TitanText Premier:
#     model_id: "amazon.titan-text-premier-v1:0"
#     #system_prompt_disabled: true
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     topP: 1.0
#     maxTokenCount: 4096
#   Amazon TitanText Express:
#     model_id: "amazon.titan-text-express-v1"
#     #system_prompt_disabled: true
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     maxTokenCount: 8000
#   OpenAI GPT4:
#     model_id: "amazon.titan-text-express-v1"
#     #system_prompt_disabled: true
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     maxTokenCount: 8000 
#   Google Gemini Gemma:
#     model_id: "amazon.titan-text-express-v1"
#     #system_prompt_disabled: true
#     input_format: "list_of_dicts"
#     temperature: 1.0
#     maxTokenCount: 8000      



    